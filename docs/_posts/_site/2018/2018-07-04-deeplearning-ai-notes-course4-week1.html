<script type="text/javascript" async="" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>

<p>本周讲述了CNN的基础。从边界检测引入卷积运算，并将2D卷积运算延伸到3D中的multi-filter，最后以LeNet-5架构为例整体介绍了CNN。</p>
<h1 id="1--convolutional-neural-networks">1- Convolutional Neural Networks</h1>
<h2 id="11--computer-vision">1.1- Computer Vision</h2>

<p>计算机视觉（computer vision）是因deep learing而快速发展的领域之一，并促进了自动驾驶、人脸识别等应用的发展以及更多的全新应用（而这些在几年前还是不可能的），计算机视觉的发展也为其他领域如语音识别提供了思路。</p>

<p>计算机视觉的例子：</p>
<ul>
  <li>Image classification</li>
  <li>Object detection</li>
  <li>Neural Style transfer</li>
</ul>

<p><img src="https://cdn.imshuai.com/images/2018/07/Xnip2018-07-01_15-33-03.jpg" alt="Xnip2018-07-01_15-33-03" /></p>

<p><strong>计算机视觉的一个挑战：图片数据转换的特征向量太大</strong>。比如一张1000x1000像素的图片，转化成向量则有1000x1000x3=3百万个输入属性。这将导致</p>
<ul>
  <li>Neural Network的结构十分复杂，参数很多，容易产生过拟合；</li>
  <li>庞大的计算量。</li>
</ul>

<p>这正是<strong>卷积神经网络</strong>（convolutional neural network, CNN）要解决的。</p>

<h2 id="12--edge-detection-example">1.2- Edge Detection Example</h2>
<p>Convolution opteration（卷积运算）是convolutional neural network的重要基石之一。</p>

<p>Edge Detection分为：</p>
<ul>
  <li>vertical edges</li>
  <li>horizontal edges</li>
</ul>

<p><img src="https://cdn.imshuai.com/images/2018/07/Xnip2018-07-01_17-11-29.jpg" alt="Xnip2018-07-01_17-11-29" /></p>

<p>举例：Vertical edge detection
vertical edge detection可以用卷积运算实现。比如检测一张6x6像素的灰度图片的vertical edge，设计一个3x3的矩阵（<strong>称之为filter或kernel</strong>），让原始图片和filter矩阵做卷积运算（convolution），得到一个4x4的图片。
具体的做法是，将filter矩阵贴到原始矩阵上（从左到右从上到下），依次可以贴出4x4种情况。让原始矩阵与filter重合的部分做element wise的乘积运算再求和，所得的值作为4x4矩阵对应元素的值。如下图是第一个元素的计算方法，以此类推。</p>

<p><img src="https://cdn.imshuai.com/images/2018/07/Xnip2018-07-01_17-20-14.jpg" alt="Xnip2018-07-01_17-20-14" /></p>

<p>下面是一个动图展示了卷积操作：</p>

<p><img src="https://cdn.imshuai.com/images/2018/07/Convolution_schematic.gif" alt="Convolution_schematic" /></p>

<p>使用卷积做边缘检测的解释：</p>

<p><img src="https://cdn.imshuai.com/images/2018/07/Xnip2018-07-01_17-25-02.jpg" alt="Xnip2018-07-01_17-25-02" /></p>

<p>如上图，通过filter卷积运算后，右边的矩阵会出现一条中间的空白，代表了边缘所在的位置。</p>

<p>我的理解：filter矩阵很有意思，它是左右堆成且只相反，如果不是边缘（即像素值比较均匀），经过filter运算后的点（相当于做了加权平均）基本被抵消为0。如果filte在边缘处运算，会造成明显的不平衡，即显示出边缘所在。</p>

<p><strong>这里的卷积，本质上是图片的某个区域与filter的内积，而内积反应的是相似性</strong>。所以用一个1,0,-1的filter找到的就是和气相似的区域，即垂直边缘。</p>

<p>关于卷积，参考资料：<a href="https://blog.csdn.net/silence2015/article/details/69936913">卷积的理解</a></p>

<h2 id="13--more-edge-detection">1.3- More Edge Detection</h2>

<ol>
  <li>亮到暗与暗到亮</li>
</ol>

<p>以vertical edge detection为例，亮到暗与暗到亮会形成两种不同的检测结果，如下图使用相同的filter，分别得到30和-30的边界：</p>

<p><img src="https://cdn.imshuai.com/images/2018/07/Xnip2018-07-01_17-39-56.jpg" alt="Xnip2018-07-01_17-39-56" /></p>

<p>因此，<strong>根据生成的边界的正负，可以得知边界的类型</strong>。</p>

<ol>
  <li>horizontal edge detection
类似，将filter做一个转置，即得到了horizontal edge detection的filter</li>
</ol>

<p><img src="https://cdn.imshuai.com/images/2018/07/Xnip2018-07-01_17-44-33.jpg" alt="Xnip2018-07-01_17-44-33" /></p>

<p>一个稍复杂的horizontal edge detection，左边是由亮到暗，右边是由暗到亮：</p>

<p><img src="https://cdn.imshuai.com/images/2018/07/Xnip2018-07-01_17-46-23.jpg" alt="Xnip2018-07-01_17-46-23" /></p>

<p>通过正负，可以得知30表示左边的水平边界是positive edge，即亮到暗，而-30则表示右半部分则是negative edge，即暗到亮。</p>

<ol>
  <li>filter的选择
除了上面的-1,0,1的filter外，还有其他类型的filter，<strong>它们加强了中心点的权重，使得算法更健壮</strong>，比如：</li>
</ol>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Sobel_operator">Sobel fitler</a>
<img src="https://cdn.imshuai.com/images/2018/07/Xnip2018-07-01_18-06-00.jpg" alt="Xnip2018-07-01_18-06-00" /></li>
  <li>Scharr filter
<img src="https://cdn.imshuai.com/images/2018/07/Xnip2018-07-01_18-05-46.jpg" alt="Xnip2018-07-01_18-05-46" /></li>
</ul>

<ol>
  <li>算法学习filter
与人工设置filter对应，也可以通过算法训练出一个filter，即将filter看成参数，使用反向传播算法学习（后续会介绍）。而且不仅限于vertical和horizontal，算法还可以学习出各种角度的filter。</li>
</ol>

<h2 id="14--padding">1.4- Padding</h2>
<p>为了构建deep neural network，对基本卷积操作的一个改进就是padding。</p>

<p>问题：通过filter卷积运算后的矩阵维度会<strong>比原矩阵变小了</strong>，比如一个6x6的矩阵经过3x3的filter卷积运算后，只有4x4的维度了。一般的，对于一个\(n\times n\)的矩阵，经过\(f\times f\)的filter运算后是\((n-f+1)\times (n-f+1)\)维。这造成两个缺陷：</p>
<ul>
  <li>图片运算后被缩小了（shrink output），如果neural network层数较多，可能会缩小的很严重，因为每一层都会缩一次。</li>
  <li>边界上的像素被运算的次数要小于中心的像素，比如左上角的像素只会参与一次卷积运算。丢失了图片边缘的信息。</li>
</ul>

<p><strong>解决的办法是padding，即在原始矩阵围一圈（通常用0填充）</strong>。比如对于3x3的fitler，把原始图片矩阵上下左右各padding一个单位（padding=1），一个6x6的矩阵padding后变成了8x8的矩阵，卷积后还是6x6的矩阵。</p>

<p><img src="https://cdn.imshuai.com/images/2018/07/Padding.jpg" alt="Padding" />
（图片来源：http://kyonhuang.top/Andrew-Ng-Deep-Learning-notes/#/Convolutional_Neural_Networks/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C）</p>

<p>考虑到是否padding，卷积运算分为了两种：</p>
<ul>
  <li>Valid convolutions
即没有padding</li>
  <li>Same convolutions
有padding，使得输出矩阵和输入矩阵保持相同的大小</li>
</ul>

<p>在计算机视觉领域，filter的大小f通常取奇数通常取奇数，为了保证输出矩阵大小不变，padding的大小则是：\(p=\frac{f-1}{2}\)</p>

<h2 id="15--strided-convolutions">1.5- Strided Convolutions</h2>
<p>前面的例子，在做卷积的时候，filter每次移动的距离是1，而Stride convolution允许移动的距离大于1，比如下图设置的stride是2：</p>

<p>结果矩阵中，第一个元素的计算是取左上角9个元素（图中蓝色部分）和filter运算，得到91</p>

<p><img src="https://cdn.imshuai.com/images/2018/07/Xnip2018-07-01_20-35-54.jpg" alt="Xnip2018-07-01_20-35-54" /></p>

<p>然后直接向右移动两格（图中蓝色部分）做卷积运算，得到第二个元素100：</p>

<p><img src="https://cdn.imshuai.com/images/2018/07/Xnip2018-07-01_20-36-54.jpg" alt="Xnip2018-07-01_20-36-54" /></p>

<p>以此类推：</p>

<p><img src="https://cdn.imshuai.com/images/2018/07/Xnip2018-07-01_20-39-42.jpg" alt="Xnip2018-07-01_20-39-42" /></p>

<p>很显然，结果矩阵比原矩阵要小，变成了只有3x3的矩阵。</p>

<p>如果原矩阵大小是\(n \times n \)，padding是\(p\)，filter矩阵大小是\(f \times f\)，stride是\(s\)，则可以计算结果矩阵的大小是：\(\biggl\lfloor \frac{n+2p-f}{s}+1   \biggr\rfloor \times \biggl\lfloor \frac{n+2p-f}{s}+1 \biggr\rfloor\)</p>

<p>关于卷积和互相关（cross-correlation）的说明:
<strong>严格来说，前面介绍的卷积和数学上的卷积定义有所差别</strong>。数学上的卷积，<strong>在乘积求和之前要先把filter矩阵沿着反斜对角线旋转一下</strong>，如下图：</p>

<p><img src="https://cdn.imshuai.com/images/2018/07/Xnip2018-07-02_08-17-37.jpg" alt="Xnip2018-07-02_08-17-37" /></p>

<p>做旋转的好处是，可以使得卷积操作满足结合律。</p>

<p>但在machine learing语境中，由于filter基本是垂直或水平的，旋转与否影响不大，故习惯上还是将cross-correlation称作convolution。</p>

<p>参考资料：<a href="https://zhuanlan.zhihu.com/p/33194385">卷积与互相关的一点探讨</a></p>

<h2 id="16--convolutions-over-volume">1.6- Convolutions Over Volume</h2>
<p>前面介绍的卷积都是应用在二维灰度图片上，现在将卷积应用于三维上（比如RGB图片）</p>

<ol>
  <li>RGB图片卷积运算的例子：</li>
</ol>

<p><img src="https://cdn.imshuai.com/images/2018/07/Xnip2018-07-02_08-58-16.jpg" alt="Xnip2018-07-02_08-58-16" /></p>

<p>RGB图片需要用三个矩阵叠加，分别表示RGB三种颜色。原始图片的size是6x6x3，<strong>图片的本身的尺寸6x6称作height和width，而叠加的层数成为channel</strong>（这里RGB构成的channel为3），对应的filter也需要三层，<strong>即filter的channel要与原始图片的channel一样</strong>。</p>

<p>运算规则是，<strong>RGB的每一个channel和filter每一个channel先做卷积，然后将每个channel的卷积加总</strong>，作为结果矩阵的对应元素值，如下图：</p>

<p><img src="https://cdn.imshuai.com/images/2018/07/Xnip2018-07-02_09-06-33.jpg" alt="Xnip2018-07-02_09-06-33" /></p>

<p>依次类推：</p>

<p><img src="https://cdn.imshuai.com/images/2018/07/Xnip2018-07-02_09-09-25.jpg" alt="Xnip2018-07-02_09-09-25" /></p>

<p>如果仅关注一种颜色（比如红色）的边界，则可以将filter中绿色和蓝色层的矩阵设置为全零矩阵。如果RGB三种颜色的边界都考虑，则将filter三层设置为一样的矩阵。</p>

<ol>
  <li>Multi filters</li>
</ol>

<p><strong>Multi filters是构建CNN的重要思想</strong>。如果我们不只想检测水平和垂直边界，比如还想检测45度，甚至70度的边界呢？换句话说，<strong>如何同时应用多个filter呢</strong>？</p>

<p>可以这样思考，图片分别应用了两个filter，比如一个是水平filter、一个是垂直filter，分别得到两个目标矩阵，都是一层channel；然后这两个矩阵叠一起就变成了一个2层channel的矩阵，如下图：</p>

<p><img src="https://cdn.imshuai.com/images/2018/07/Xnip2018-07-02_09-25-52.jpg" alt="Xnip2018-07-02_09-25-52" /></p>

<p><strong>输出矩阵的channel数则与应用的filter的个数一样</strong>。</p>

<p>multi-filter使得算法可以学习出多种feature。如果把一个filter整体看成基本神经网络中的参数w的话，那么multi-filter就相当于多个w。在基本神经网络中，我们也有W的行数和输出矩阵的行数一样，这一点类似filter个数和输出矩阵的channel的关系。</p>

<p>另外一张RGB图片，可以认为天然的被拆分成3个feature。</p>

<p><strong>综上所述，你可以同时应用多个filter，并且每个filter又有多个channel，在这个基础上就可以实现CNN了。</strong></p>

<h2 id="17--one-layer-of-a-convolutional-network">1.7- One Layer of a Convolutional Network</h2>

<p>一个单层的卷积神经网络例子如下：</p>

<p><img src="https://cdn.imshuai.com/images/2018/07/One-Layer-of-a-Convolutional-Network.jpg" alt="One-Layer-of-a-Convolutional-Network" />
（图片来源：http://kyonhuang.top/Andrew-Ng-Deep-Learning-notes/#/Convolutional_Neural_Networks/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C?id=%E5%8D%95%E5%B1%82%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C）</p>

<p>输入一张RGB图片，经过两个filter得到卷积，在卷积结果上加上偏移b1和b2，再应用activation function，得到输出层。</p>

<p>下面是动画演示，很形象：</p>

<video width="700" controls="">
  <source src="https://cdn.imshuai.com/video/2018/07/conv_kiank.mp4" type="video/mp4" />
Your browser does not support the video tag.
</video>

<p>对比基本的Neural Network，可以发现filter类似于参数\(W^{[1]}\)。</p>

<p>而卷积运算在加上后的b，即，也可以看做是原图像和filter上每个元素的线性组合，这也类似于基本Neural Network中计算z的过程：\(z^{[1]}=W^{[1]}a^{[0]} + b^{[1]}\)</p>

<p><strong>每一个channel可以理解为普通NN中的一个实数w。</strong></p>

<p>参数个数
问：如果一个layer有10个filter，每个filter是3x3x3，本层一共有多少参数？
答：一个filter有27个参数，再加上一个bias参数b，一个filter对应28个参数，10个filter一共280个参数。</p>

<p>与基本NN不同，CNN的参数个数并不随输入增大（共享参数的原因，后面会介绍），无论是1000x1000像素的图片，还是5000x5000像素的图片，CNN的参数都可以是一样的值。<strong>CNN极大的减少了parameter的个数，不会随着图片的像素数增加而增加，降低了overfitting</strong>。</p>

<p><strong>符号总结（符号和维度顺序惯例）：</strong></p>
<ul>
  <li>\(l\)：表示CNN的层数是第\(l\)层，用上标\([l]\)标记哪一层的参数。</li>
  <li>\(f^{[l]}\)：filter的大小，即filter矩阵的长或宽，一般长宽相等。</li>
  <li>\(p^{[l]}\)：padding的大小</li>
  <li>\(s^{[l]}\)：stride步长</li>
  <li>\(n_C^{[l]}\)：输出的channel数，也是当前层filter的个数，下一层filter的channel数</li>
  <li>\(n_H^{[l]}\)：图片矩阵的height</li>
  <li>\(n_W^{[l]}\)：图片矩阵的width</li>
</ul>

<p>对\([l]\)层来说：</p>
<ul>
  <li>输入维度是：\(n_H^{[l-1]} \times n_W^{[l-1]} \times n_C^{[l-1]}\)</li>
  <li>输出维度是：\(n_H^{[l]} \times n_W^{[l]} \times n_C^{[l]}\)</li>
  <li>单个filter的维度是：\(f^{[l]} \times f^{[l]} \times n_C^{[l-1]}\) （注意：本层filter的channel和上一层输出的channel一样）</li>
  <li>所有filter（\(n_C^{[l-1]} \)个）组成当前layer的Weight：\(f^{[l]} \times f^{[l]} \times n_C^{[l-1]} \times n_C^{[l]} \)</li>
  <li>bias的维度是：\(1 \times 1 \times 1 \times n_C^{[l]}\)</li>
  <li>activations（\(a^{[l]}\)）的维度和输出维度一样：\(n_H^{[l]} \times n_W^{[l]} \times n_C^{[l]}\)</li>
  <li>对于batch gradient，考虑到样本数\(m\)，则\(A^{[l]}\)的维度是\(m \times n_H^{[l]} \times n_W^{[l]} \times n_C^{[l]}\)，编程实践上也采用这个顺序的维度。</li>
</ul>

<p>根据之前的公式，有输出height、width和输入的关系如下：</p>

<script type="math/tex; mode=display">n_H^{[l]} = \biggl\lfloor \frac{n_H^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1   \biggr\rfloor</script>

<script type="math/tex; mode=display">n_W^{[l]} = \biggl\lfloor \frac{n_W^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1   \biggr\rfloor</script>

<h2 id="18--simple-convolutional-network-example">1.8- Simple Convolutional Network Example</h2>

<p>下图是一个简单CNN网络的例子：</p>

<p><img src="https://cdn.imshuai.com/images/2018/07/Xnip2018-07-04_08-28-33.jpg" alt="Xnip2018-07-04_08-28-33" /></p>
<ul>
  <li>输入图片是39x39x3的维度。</li>
  <li>最后的输出volume，unroll成一个vector，再通过logistic或softmax函数处理，实现分类。</li>
  <li>一般而言，<strong>图片的height \(n_H^{[l]}\) 和width \(n_W^{[l]}\)随着层数的增加逐渐降低，但channel \(n_C^{[l]}\)逐渐增加</strong>。</li>
</ul>

<p>Type of layer in a converlutional netwrok(ConvNet):</p>
<ul>
  <li>Convolution (CONV)</li>
  <li>Pooling (POOL)</li>
  <li>Fully connected (FC)</li>
</ul>

<h2 id="19--pooling-layers">1.9- Pooling Layers</h2>
<ol>
  <li>除了卷积层（convolutional layers）外，卷积网络（ConvNets）还经常用池化层（pooling layers），主要好处是：
    <ul>
      <li>降低表示的大小，加快计算速度。</li>
      <li>提高feature的鲁棒性。</li>
    </ul>
  </li>
</ol>

<p>pooling可分为max pooling和average pooling。</p>

<ol>
  <li>Max pooling</li>
</ol>

<p>下图是max pooling的示意图：</p>

<p><img src="https://cdn.imshuai.com/images/2018/07/Xnip2018-07-04_08-45-20.jpg" alt="Xnip2018-07-04_08-45-20" /></p>

<p>Max pooling的过程是，<strong>将原矩阵分成若干个分区（如上图四种颜色标记），每个分区内选择最大值，代表这个分区，组成一个新的矩阵</strong>。
上面的例子的作用结果（尤其是矩阵大小），<strong>也相当于一个作用了一个卷积filter</strong>，其大小是2x2，stride为2的。即：\(f=2\)，\(s=2\)，之前推导的filter大小公式也适用。因此<strong>max pooling也用\(f\)和\(s\)等作为其参数，但需要注意，对max pooling而言，这些参数是超参</strong>。</p>

<p>与卷积相比，max pooling并没有一个filter，或者说这个filter是一个全1矩阵，和重叠的矩阵元素相乘，然后取元素最大值，从这点看和卷积操作也是统一的。</p>

<p>下图是一个f=3, s=1的max pooling例子：</p>

<p><img src="https://cdn.imshuai.com/images/2018/07/Xnip2018-07-04_08-59-04.jpg" alt="Xnip2018-07-04_08-59-04" /></p>

<p><img src="https://cdn.imshuai.com/images/2018/07/Xnip2018-07-04_09-00-06.jpg" alt="Xnip2018-07-04_09-00-06" /></p>

<p>类似的，max pooling也是支持channel的，但与卷积不同，<strong>输出的channel和输入的channel数目是一样的</strong>（卷积输出channel总是一层，卷积相当于计算后的channel做了叠加，<strong>max pooling的channel之间互相独立</strong>）。</p>

<p><img src="https://cdn.imshuai.com/images/2018/07/Xnip2018-07-04_09-15-12.jpg" alt="Xnip2018-07-04_09-15-12" /></p>

<p>关于max pooling的直觉解释：
元素较大的值，可能是卷积过程中提取到的某些特征（比如边界），而max pooling则在压缩了矩阵大小的情况下，保留每个分区内最大的输出，即保留了提取的特征。但理论上还没有证明max pooling的原理，max pooling应用的原因是在实践中效果很好。</p>

<ol>
  <li>Average pooling</li>
</ol>

<p>与max pooling的不同仅在于最后取的是分区内的平均值，而不是最大值。比如：</p>

<p><img src="https://cdn.imshuai.com/images/2018/07/Xnip2018-07-04_09-20-10.jpg" alt="Xnip2018-07-04_09-20-10" /></p>

<p>另外，Average pooling不如max pooling那么常用。</p>

<ol>
  <li>pooling总结：
    <ul>
      <li>超参：</li>
    </ul>
    <ul>
      <li>f：filter size（通常选择f=2,s=2，实现对一张图片的shrink，长宽都shrink了一半）</li>
      <li>s：stride</li>
      <li>选择max还是average pooling</li>
      <li>p：padding，几乎不会用到（因为pooling本身就是一个shrink的过程），或设置为0.
    * pooling没有需要学习的参数，只有超参。</li>
    </ul>
  </li>
</ol>

<h2 id="110--cnn-example">1.10- CNN Example</h2>
<p>前面已经了解了CNN需要的模块，下面通过一个例子介绍CNN网络：LeNet-5架构（与原论文略有修改），用来识别数字。
LeNet-5原版可参考论文：http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf</p>

<p>LeNet-5架构如下：</p>

<p><img src="https://cdn.imshuai.com/images/2018/07/CNN.jpg" alt="Xnip2018-07-04_21-11-41" /></p>

<ul>
  <li>通常Conv Layer和Pooling Layer合在一起算一个layer，因为pooling layer并没有参数训练</li>
  <li>常见的结构：Conv ==&gt; Pool ==&gt; Conv ==&gt; Pool ==&gt; FC ==&gt; FC ==&gt; softmax</li>
  <li>最终还会用FC层（全连接层），与一般NN的处理一样；并在输出层，应用softmax得到10个数字的概率。</li>
  <li>在整个网络中，Height和Width是逐渐递减的，但channel和filter是递增的。</li>
  <li>关于CNN如何选择超参：可以参考论文的经验。</li>
</ul>

<p>整个例子的参数个数如下：</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center"> </th>
      <th style="text-align: center">Activation shape</th>
      <th style="text-align: center">Activation Size</th>
      <th style="text-align: center">#parameters</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><strong>Input:</strong></td>
      <td style="text-align: center">(32, 32, 3)</td>
      <td style="text-align: center">3072</td>
      <td style="text-align: center">0</td>
    </tr>
    <tr>
      <td style="text-align: center"><strong>CONV1(f=5, s=1)</strong></td>
      <td style="text-align: center">(28, 28, 6)</td>
      <td style="text-align: center">4704</td>
      <td style="text-align: center">156 (=5*5*6+6)</td>
    </tr>
    <tr>
      <td style="text-align: center"><strong>POOL1</strong></td>
      <td style="text-align: center">(14, 14, 6)</td>
      <td style="text-align: center">1176</td>
      <td style="text-align: center">0</td>
    </tr>
    <tr>
      <td style="text-align: center"><strong>CONV2(f=5, s=1)</strong></td>
      <td style="text-align: center">(10, 10, 16)</td>
      <td style="text-align: center">1600</td>
      <td style="text-align: center">416 (=5*5*16+16)</td>
    </tr>
    <tr>
      <td style="text-align: center"><strong>POOL2</strong></td>
      <td style="text-align: center">(5, 5, 16)</td>
      <td style="text-align: center">400</td>
      <td style="text-align: center">0</td>
    </tr>
    <tr>
      <td style="text-align: center"><strong>FC3</strong></td>
      <td style="text-align: center">(120, 1)</td>
      <td style="text-align: center">120</td>
      <td style="text-align: center">48120 (=120*400+120)</td>
    </tr>
    <tr>
      <td style="text-align: center"><strong>FC4</strong></td>
      <td style="text-align: center">(84, 1)</td>
      <td style="text-align: center">84</td>
      <td style="text-align: center">10164 (=84*120+84)</td>
    </tr>
    <tr>
      <td style="text-align: center"><strong>Softmax</strong></td>
      <td style="text-align: center">(10, 1)</td>
      <td style="text-align: center">10</td>
      <td style="text-align: center">850 (=10*84+10)</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>pooling layer没有参数</li>
  <li>CONV layer的参数相比FC的parameter会少很多。</li>
  <li>activation size递减 （activation size总是和feature相等的，feature一直在缩减）</li>
</ul>

<h2 id="111--why-convolutions">1.11- Why Convolutions?</h2>

<p>CONV Layer相比一般神经网络的全连接层的优势：</p>
<ul>
  <li>
    <p>参数共享（parameter sharing）
以上一节的例子为例，如果在第一层就用FC的话，参数可达4704*3070 + 4704个，这个数字已经膨胀到了1400万，而这还仅是训练一个只有32*32像素的小图片。
而CONV Layer只有156个参数。
参数共享为什么可行呢？<strong>一个feature检测器，即filter（比如垂直边界检测）在图片的一个地方适用，也很可能在图片的其他地方适用</strong>（我的理解：在这一点上很像transfering learning或multi-task learning）。这种共享不仅在底层feature有用，也在高层feature有用（比如检测眼睛）。</p>
  </li>
  <li>
    <p>稀疏连接（sparsity of connections）
稀疏连接是指，输出中的每个单元仅和输入的一个小分区相关，比如输出的左上角的像素仅仅由输入左上角的9个像素决定（假设filter大小是3*3），而其他输入都不会影响。</p>
  </li>
</ul>

<p><strong>基于上述的特点，CNN网络可以使用较少的参数，使用较少的训练数据，并且不容易overfitting。
另外CNN也特别适合捕捉平移不变形（Translation Invariance）</strong>。</p>

<p>附：直观展示CNN网络：http://scs.ryerson.ca/~aharley/vis/</p>
